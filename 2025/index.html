<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Eval4NLP - 2025</title>

  <!-- Bootstrap core CSS -->
  <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="../vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">

  <!-- Custom styles for this template -->
  <link href="../css/clean-blog.css" rel="stylesheet">
  <link href="../css/custom.css" rel="stylesheet">

  <!-- Bootstrap core JavaScript -->
  <script src="../vendor/jquery/jquery.min.js"></script>
  <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="../js/clean-blog.min.js"></script>
  <script>
    $(function () {
      $("#navbarResponsive").load("nav.html");
    });
  </script>
</head>

<body>

  <!-- Navigation -->
  <nav class="navbar  navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand text-white" href="index.html">Eval4NLP 2025</a>
      <button class="navbar-toggler navbar-toggler-right text-white" type="button" data-toggle="collapse"
        data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
        aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">

      </div>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('img/home-bg.jpg')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="site-heading">
            <h1>Eval4NLP 2025</h1>
            <span class="subheading">The 5<sup>th</sup> Workshop on "Evaluation & Comparison of NLP Systems"</span>
            <span class="subheading"><b>23<sup>rd</sup>-24<sup>th</sup> December 2025</b>, co-located at <a
                href="https://www.afnlp.org/conferences/ijcnlp2025/#schedule" target="blank">AACL 2025</a></span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Main Content -->
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        <!-- <h2 class="section-heading">Latest News</h2>
        <br>
        <table class="table">
          <tbody>
            <tr><th scope="row">Month Day, Year</th><td>Content</td></tr></tbody>
        </table> -->

        <h2 class="section-heading">Important Dates</h2>
        <p>All deadlines are 11.59 pm UTC -12h (“Anywhere on Earth”).
        <ul>
          <li><b>TBA</b> TBA</li>
        </ul>
        </p>
        <div>
          <p>
            New: This year, the workshop focuses on developing model evaluation and human evaluation strategies
            for multitasking, multilingual, and multimodal scenarios, with special consideration for low-resource and
            highly distant languages. Other key topics include designing evaluation metrics,
            creating adequate evaluation data, and reporting correct results.
          </p>
        </div>
        <h2 class="section-heading">Overview</h2>
        <p>
          Fair evaluations and comparisons are of fundamental importance to the NLP community to properly track
          progress,
          especially within the current deep learning revolution, with new state-of-the-art results reported in ever
          shorter
          intervals. This concerns the creation of benchmark datasets that cover typical use cases and blind spots of
          existing systems, the design of metrics for evaluating the performance of NLP systems along different
          dimensions,
          and the reporting of evaluation results in an unbiased manner.
        </p>
        <p>
          While some workshops (e.g., Metrics Tasks at WMT, NeuralGen, HumEval, EvalNLGEval, GEM, and New Frontiers
          in Summarization) have tackled certain aspects of NLP evaluation, recent advancements have enabled models
          to be general purpose while handling multiple tasks (i.e, language understanding, summarization, dialogue,
          question answering, reasoning, etc.) across multiple languages and modalities. This progress has introduced
          challenges, such as the need for robust evaluation methods, diverse datasets, and reliable result reporting.
          There is a growing demand for evaluation strategies that address multitasking, multilingual, and multimodal
          scenarios. The first workshop in the series, <a href="https://nlpevaluation2020.github.io/index.html"
            target="blank">Eval4NLP’20</a> (collocated with EMNLP’20), was the first workshop to take a broad and
          unifying perspective on the subject matter. The second (<a href="2021/index.html"
            target="blank">Eval4NLP’21</a> collocated with EMNLP’21), third (<a href="2022/index.html"
            target="blank">Eval4NLP’22</a> collocated with AACL’22) and fourth (<a href="2023/index.html"
            target="blank">Eval4NLP’24</a> collocated with AACL’23) workshop extended this
          perspective. The fifth Eval4NLP workshop aims to promote model evaluation and human evaluation strategies for
          these recent complex settings.
        </p>

        <p>Further topics of interest of the workshop include (but not limited to):</p>

        <ol>
          <li>
            <b>Designing evaluation metrics and evaluation methodology</b><br>
          </li>

          <li>
            <b>Creating adequate evaluation data and evaluation test suites</b><br>
          </li>

          <li>
            <b>Reporting correct and reproducible results</b><br>
          </li>
        </ol>
        <p>See <a href="cfp.html" class="underline">call for papers</a> for more details. Further, reference papers <a
            href="reference.html" class="underline">here</a>.</p>
        <br>
        <h3>Contact us</h3>
        <p>Email: <a href="mailto:eval4nlp@gmail.com">eval4nlp@gmail.com</a></p>
        <br>
      </div>
    </div>
  </div>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://twitter.com/nlp_evaluation">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="mailto:eval4nlp@gmail.com">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">
            Copyright &copy; Eval4NLP 2025<br>
          </p>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>